{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8c25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from finta import TA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# List of symbols for technical indicators\n",
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'EMV']\n",
    "\n",
    "fpt_csv=pd.read_csv(r\"C:/Users/luong/Desktop/finpros round 2/FPT.csv\")\n",
    "df = pd.DataFrame(fpt_csv)\n",
    "data = pd.DataFrame(df[[\"Close\", \"High\",\"Low\",\"Volume\",\"Open\"]])\n",
    "data.rename(columns={\"Close\": 'close', \"High\": 'high', \"Low\": 'low', 'Volume': 'volume', 'Open': 'open'}, inplace=True)\n",
    "print(data.head())\n",
    "data = data[-10000:]\n",
    "data.reset_index(inplace=True)\n",
    "del (data[\"index\"])\n",
    "\n",
    "def _exponential_smooth(data, alpha):\n",
    "\n",
    "    return data.ewm(alpha=alpha).mean()\n",
    "\n",
    "data = _exponential_smooth(data, 0.65)\n",
    "\n",
    "def _get_indicator_data(data):\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = data.merge(ind_data, left_index=True, right_index=True)\n",
    "    data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    data['ema50'] = data['close'] / data['close'].ewm(50).mean()\n",
    "    data['ema21'] = data['close'] / data['close'].ewm(21).mean()\n",
    "    data['ema15'] = data['close'] / data['close'].ewm(14).mean()\n",
    "    data['ema5'] = data['close'] / data['close'].ewm(5).mean()\n",
    "\n",
    "    data['normVol'] = data['volume'] / data['volume'].ewm(5).mean()\n",
    "\n",
    "    del (data['open'])\n",
    "    del (data['high'])\n",
    "    del (data['low'])\n",
    "    del (data['volume'])\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = _get_indicator_data(data)\n",
    "print(data.columns)\n",
    "\n",
    "def _produce_prediction(data, window):\n",
    "\n",
    "    prediction = (data.shift(-window)['close'] >= data['close'])\n",
    "    prediction = prediction.iloc[:-window]\n",
    "    data['pred'] = prediction.astype(int)\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = _produce_prediction(data, window=15)\n",
    "del (data['close'])\n",
    "data = data.dropna()\n",
    "\n",
    "def _train_random_forest(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "    params_rf = {'n_estimators': [110,130,140,150,160,180,200]}\n",
    "    rf_gs = GridSearchCV(rf, params_rf, cv=5)\n",
    "    rf_gs.fit(X_train, y_train)\n",
    "    rf_best = rf_gs.best_estimator_\n",
    "    print(rf_gs.best_params_)\n",
    "    \n",
    "    prediction = rf_best.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return rf_best\n",
    "\n",
    "def _train_KNN(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    knn = KNeighborsClassifier()\n",
    "    params_knn = {'n_neighbors': np.arange(1, 25)}\n",
    "    knn_gs = GridSearchCV(knn, params_knn, cv=5)\n",
    "    knn_gs.fit(X_train, y_train)\n",
    "    knn_best = knn_gs.best_estimator_\n",
    "    print(knn_gs.best_params_)\n",
    "    \n",
    "    prediction = knn_best.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return knn_best\n",
    "\n",
    "def _ensemble_model(rf_model, knn_model, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    estimators=[('knn', knn_model), ('rf', rf_model)]\n",
    "    ensemble = VotingClassifier(estimators, voting='hard')\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    print(ensemble.score(X_test, y_test))\n",
    "    \n",
    "    prediction = ensemble.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "def cross_Validation(data):\n",
    "\n",
    "    num_train = 10\n",
    "    len_train = 40\n",
    "\n",
    "    rf_RESULTS = []\n",
    "    knn_RESULTS = []\n",
    "    ensemble_RESULTS = []\n",
    "    \n",
    "    i = 0\n",
    "    while True:\n",
    "\n",
    "        df = data.iloc[i * num_train : (i * num_train) + len_train]\n",
    "        i += 1\n",
    "        print(i * num_train, (i * num_train) + len_train)\n",
    "        \n",
    "        if len(df) < 40:\n",
    "            break\n",
    "        \n",
    "        y = df['pred']\n",
    "        features = [x for x in df.columns if x not in ['pred']]\n",
    "        X = df[features]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size= 7 * len(X) // 10,shuffle=False)\n",
    "        \n",
    "        rf_model = _train_random_forest(X_train, y_train, X_test, y_test)\n",
    "        knn_model = _train_KNN(X_train, y_train, X_test, y_test)\n",
    "        ensemble_model = _ensemble_model(rf_model, knn_model, X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        rf_prediction = rf_model.predict(X_test)\n",
    "        knn_prediction = knn_model.predict(X_test)\n",
    "        ensemble_prediction = ensemble_model.predict(X_test)\n",
    "        \n",
    "        print('rf prediction is ', rf_prediction)\n",
    "        print('knn prediction is ', knn_prediction)\n",
    "        print('ensemble prediction is ', ensemble_prediction)\n",
    "        print('truth values are ', y_test.values)\n",
    "        \n",
    "        rf_accuracy = accuracy_score(y_test.values, rf_prediction)\n",
    "        knn_accuracy = accuracy_score(y_test.values, knn_prediction)\n",
    "        ensemble_accuracy = accuracy_score(y_test.values, ensemble_prediction)\n",
    "        \n",
    "        print(rf_accuracy, knn_accuracy, ensemble_accuracy)\n",
    "        rf_RESULTS.append(rf_accuracy)\n",
    "        knn_RESULTS.append(knn_accuracy)\n",
    "        ensemble_RESULTS.append(ensemble_accuracy)\n",
    "        \n",
    "        \n",
    "    print('RF Accuracy = ' + str( sum(rf_RESULTS) / len(rf_RESULTS)))\n",
    "    print('KNN Accuracy = ' + str( sum(knn_RESULTS) / len(knn_RESULTS)))\n",
    "    print('Ensemble Accuracy = ' + str( sum(ensemble_RESULTS) / len(ensemble_RESULTS)))\n",
    "\n",
    "cross_Validation(data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322afe7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5041ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53180feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
